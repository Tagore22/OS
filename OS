1강
 - 컴퓨터를 단순히 미지의 대상에서 분석의 대상으로 인식하기 위해 컴퓨터 구조와 OS에 대해 알아야 한다
 - 문법에 맞는 소스 코드를 컴퓨터에 입력만 하는 개발자를 넘어 컴퓨터를 내려다보며 문제를 해결할 수 있는
 개발자를 지향해야 한다
 - 컴퓨터의 성능, 용량, 비용에 대해 알아야 한다

2강
 컴퓨터 구조의 큰 그림

컴퓨터가 이해하는 두 가지 정보
1. 데이터
- 숫자, 문자, 이미지, 동영상과 같은 정적인 정보
- 컴퓨터와 주고 받는 내부에 저장된 정보를 데이터라 통칭함
- 0과 1로 숫자와 문자를 표현하는 방법
2. 명령어
- 컴퓨터는 결국 명령어를 처리하는 기계
- 컴퓨터를 실질적으로 움직이는 정보
- 데이터는 명령어를 위한 일종의 재료
- 명령어의 생김새와 동작 방식

컴퓨터의 4가지 핵심 부품
1. CPU
- 산술논리연산장치(계산기)인 ALU, CPU내의 저장을 위한 레지스터, 제어 신호를 내보내고 명령어를 해석하는
제어장치 3개로 구분할 수 있다
- 메모리에 저장된 값을 읽어 들이고, 해석하고, 실행하는 장치다
2. 메모리
- 현재 실행되는 프로그램(프로세스)의 명령어와 데이터를 저장하는 부품(RAM)
- 휘발성의 RAM과 비휘발성의 ROM으로 나뉘며 RAM에는 하드디스크의 저장된 데이터를 CPU에서 사용하기 위해
저장하고 ROM에는 부팅시스템 같은 읽기만 하는 데이터가 미리 저장되어 있다
- 프로그램이 실행되기 위해서는 메모리에 저장되어 있어야 한다
- 메모리는 실행되는 프로그램의 명령어와 데이터를 저장한다
- 메모리에 저장된 값의 위치는 주소로 알 수 있다
3. 보조기억장치
- 휘발성 있는 RAM을 대비하여 비휘발성의 보조기억장치가 존재한다
- 하드디스크, SSD 등이 해당함
4. 입출력장치
- 키보드, 모니터, 프린트 등이 해당한다
5. 메인보드
- 메인보드에 연결된 부품은 버스를 통해 정보를 주고 받음
- 버스는 컴퓨터의 부품끼리 정보를 주고 받는 일종의 통로
- 다양한 종류의 버스가 있으나 핵심 부품을 연결하는 버스는 시스템 버스

시스템 버스의 내부 구성
1. 주소 버스
- 주소를 주고 받는 통로
2. 데이터 버스
- 명령어와 데이터를 주고 받는 버스
3. 제어 버스
- 제어 신호를 주고 받는 버스
- 읽기와 쓰기 모두 3가지 버스를 전부 사용한다
- 읽을때에는 읽는 신호, 몇번지 값을 읽는지에 대해 제어 버스와 주소 버스를 사용하고 해당 데이터를 읽어들일때
데이터 버스를 사용한다
- 쓸때에는 쓰는 신호, 몇번지에 쓰는지, 쓸값을 이동시키기 위해 제어 버스, 주소 버스, 데이터 버스를 사용한다

3강
 컴퓨터의 4가지 핵심 부품 직접 보기로 대체

4강
 0과 1로 숫자를 표현하는 방법
정보 단위
1. 비트
- 비트란 0과 1을 표현하는 가장 작은 정보 단위를 뜻한다
- n비트로 2의 n제곱가지의 정보 표현 가능
- 프로그램은 많은 비트로 이루어져 있음
- 다만 평소에 800만 비트라고 표현하지 않고 바이트, 킬로바이트, 메가바이트, 기가바이트, 테라바이트 등으로
표현함
- 1바이트 == 8비트
- 1킬로바이트 == 1000바이트
- 1메가바이트 == 1000킬로바이트
- 1기가바이트 == 1000메가바이트
- 1테라바이트 == 1000기가바이트
2. 워드
- CPU가 한 번에 처리할 수 있는 정보의 크기 단위
- 각 CPU마다 달라진다
- 하프 워드는 워드의 절반 크기, 풀 워드는 워드 크기, 더블 워드는 워드의 두 배 크기를 의미함

3. 이진법: 0과 1로 숫자 표현하기
- 0과 1로 수를 표현하는 방법
- 숫자가 1을 넘어가는 시점에 자리올림
- 우리가 일상적으로 사용하는 진법은 숫자가 9를 넘어갈 때 자리올림하는 십진법(Decimal)
- 0과 1로 음수를 표현할 때에는 2의 보수값을 사용한다
- 모든 0과 1을 뒤집고 1을 더한 값이 2의 보수값, 즉 음수값이 된다

4. 16진법
- 이진법으로는 숫자의 길이가 너무 길어진다(ex 십진법의 32 == 이진수 100000)
- 그래서 컴퓨터의 데이터를 표현할 때 16진법도 많이 사용
- 2진법에서 16진법으로의 변환은 4개씩 나누어 16진법으로 변환해서 합치면 되고, 그 반대는
1개씩 나누어 2진법으로 변환하여 합치면 된다

5강
 0과 1로 문자를 표현하는 방법
문자 집합과 인코딩
- 문자 집합(Character Set)이란 컴퓨터가 이해할 수 있는 문자의 모음
- 인코딩(Encoding)이란 코드화하는 과정을 말하며, 문자를 0과 1로 이루어진 문자 코드로
변환하는 과정을 말한다
- 디코딩(Decoding)이란 코드를 해석하는 과정을 말하며, 0과 1로 표현된 문자 코드를 문자로
변환하는 과정을 말한다

아스키 코드
- 초창기 문자 집합 중 하나
- 알파벳, 아라비아 숫자, 일부 특수 문자 및 제어 문자
- 7비트로 하나의 문자를 포현하며, 8비트중 1비트는 오류 검출을 위해 사용되는 패리티 비트(
Parity bit)로 사용된다

한글의 인코딩
- 한글의 인코딩에는 단어하나를 만든후 코드를 부여하는 완성형 인코딩과 각 모음 혹은 자음에
코드를 부여하여 합치는 조합형 인코딩이 존재한다
- 모든 한글을 표현하기에는 제한이 존재한다

유니코드 문자 집합과 UTF-8
- 통일된 문자 집합
- 한글, 영어, 화살표와 같은 특수 문자, 심지어 이모티콘까지 가능함
- 현재 문자 표현에 있어 매우 중요한 위치
- 유니코드의 인코딩 방식에는 UTF-8뿐만 아니라 UTF-16, UTF-32 등이 존재한다

UTF-8 인코딩
- UTF(Unicode Transformation Format) == 유니코드 인코딩 방법
- 가변 길이 인코딩이며 그 결과가 1 ~ 4바이트이다
- 인코딩 결과가 몇 바이트가 될지는 유니코드에 부여된 값에 따라 다르다

6강
 소스코드와 명령어
고급 언어와 저급 언어
- 고급 언어에는 사용자가 사용하는 c++, c, java 등이 있다
- 저급 언어에는 0과 1로 이루어진 기계어, 기계어를 읽기 편한 언어로 번역한 어셈블리어가 있다

컴파일 언어와 인터프리트 언어
- 컴파일 언어는 잘 알고 있는 그것이다. 인클루드된 헤더로 링크되며, 소스 코드 전체를 읽어가며
오류 검출 등을 하여 컴파일러가 목적 코드로 변환한다
- 인터프리트 언어는 한줄씩 실행하기 때문에 소스 코드 전체가 저급 언어로 변환되기를 기다릴 필요가 없다
- 컴파일 언어는 하나라도 오류가 있으면 실행 자체가 안되지만, 인터프리트 언어는 오류가 존재할 시
오류 이전까지는 올바르게 실행됨

7강
 C언어의 컴파일 과정
 1. 전처리기
 - 본격적으로 컴파일하기 전에 처리할 작업들
 - 외부에 선언된 다양한 소스 코드, 라이브러리 포함(ex. #include) 주의할점은 선언이 들어있는
 헤더파일들만 복사하여 옮긴다
 - 프로그래밍의 편의를 위해 작성된 매크로 변환(ex. #define)
 - 컴파일할 영역 명시(ex. #if, #ifdef)
 - 인클루드된 헤더 파일을 소스 코드로 복사하여 붙여넣는다
 - 말 그대로 붙여넣기만 하기 때문에 코드가 추가될 뿐 변환되는 것은 없다
 2. 컴파일러
 - 전처리가 완료 되어도 여전히 소스 코드
 - 전처리 완료된 소스 코드를 저급 언어(어셈블리 언어)로 변환
 3. 어셈블러
 - 어셈블리어를 기계어로 변환
 - 목적 코드(Object Code)를 포함하는 목적 파일이 됨
 - 목적 파일과 실행 파일은 둘 다 기계어로 이루어진 파일이긴 하지만 다름
 - 목적 파일이 링커의 의해 링킹을 거친 후에야 실행 파일이 된다
 4. 링커
 - 인클루드 된 헤더파일에 존재하는 함수나 전역 변수를 호출할시 전처리시에 헤더만 포함시켰기 때문에 
 선언만 있고 구현이 없는 상황이기에 동적 링크(구현문이 있는 위치를 남겨둠) 혹은 정적 링크(실제 구현문을
 복사하여 옮김)로 대체하여 실행 파일을 만든다

8강
 명령어의 구조와 주소 지정 방식

명령어의 구조
- 무엇을 대상으로, 무엇을 수행해라의 형태
- 연산 코드(수행할 연산)와 오퍼랜드(연산에 사용될 데이터 혹은 데이터가 저장된 위치)로 구성되어 있다
- 기계어, 어셈블리어도 명령어다
- 오퍼랜드는 상황에 따라 0개 이상이다
- 데이터보다 위치의 주소를 더 많이 저장하게 되는데 데이터보다 주소의 크기가 더 적기 때문에
더 많은 양을 담을 수 있기 때문이다

명령어 주소 지정 방식
- 연산에 사용할 데이터가 저장된 위치를 찾는 방법
- 유효 주소를 찾는 방법

다양한 명령어 주소 지정 방식들
1. 즉시 주소 지정 방식
- 연산에 사용할 데이터를 오퍼랜드 필드에 직접 명시
- 가장 간단한 형태의 주소 지정 방식
- 연산에 사용할 데이터의 최대 크기가 작아질 수 있지만, 빠르다
2. 직접 주소 지정 방식
- 오퍼랜드 필드에 유효 주소를 직접적으로 명시
- 유효 주소를 표현할 수 있는 크기가 연산 코드만큼 줄어듬
3. 간접 주소 지정 방식
- 오퍼랜드 필드에 유효 주소의 주소를 명시
- 앞선 주소 지정 방식들에 비해 속도가 제일 느림
- 직접 주소 지정 방식에서는 데이터가 존재하는 고유한 주소값을 사용하기 때문에 모든 명령어에
각기 다른 주소값이 포함되지만, 간접 주소 지정 방식에서는 하나의 주소값에 여러개의 주소값을
담을 수 있기에 매번 명령어마다 주소값을 필요로 하지 않는다
결과적으로 메모리는 3번이 제일 유리하고, 속도면에서는 1번이 제일 유리하다
4. 레지스터 주소 지정 방식
- 연산에 사용할 데이터가 저장된 레지스터 명시
- 메모리에 접근하는 속도보다 레지스터에 접근하는 것이 빠름
5. 레지스터 간접 주소 지정 방식
- 연산에 사용할 데이터를 메모리에 저장
- 그 주소를 저장한 레지스터를 오퍼랜드 필드에 명시
- 간접 주소 지정 방식과 비슷하게 하나에 레지스터를 통해 여러개의 주소에 접근할 수 있기에
메모리를 적게 차지한다

9강
 CPU의 내부 구성 - ALU와 제어장치

플래그 레지스터
- CPU 내부에 존재하는 특수한 레지스터로써, 연산 결과의 부호, 제로 여부, 올림 및 내림, 오버플로우,
인터럽트 가능 여부, 커널 모드 혹은 사용자 모드인지에 대해 저장한다

제어 장치
- 컴퓨터의 모든 부품을 움직일 수 있게 하는 시간 단위를 클럭이라고 한다
- 제어 장치는 플래그 레지스터, 명령어 레지스터로부터 데이터를 저장하고, ALU, 메모리, 레지스터, 입출력장치로
신호를 전달한다

10강
 CPU의 내부 구성 - 레지스터

레지스터
- CPU 내부의 작은 임시저장장치이며 프로그램 속 명령어와 데이터는 실행 전후로 
레지스터에 저장된다
- CPU 내부에는 다양한 레지스터가 존재하며 각기 다른 역할을 가진다
1. 프로그램 카운터
- 메모리에서 가져올 명령어값의 주소
2. 명령어 레지스터
- 해석할 명령어. 이것을 제어 장치가 해석함
3. 메모리 주소 레지스터
- 주소 버스를 통해 읽어야하는 메모리의 주소를 저장
4. 메모리 버퍼 레지스터
- 데이터 버스를 통해 읽어들이는 실제값(데이터 혹은 명령어)
5. 플래그 레지스터
- 연산 결과 또는 CPU 상태에 대한 부가적인 정보
6. 범용 레지스터
- 다양하고 일반적인 상황에서 자유롭게 사용. 주소만 담을 수 있는 메모리 주소 레지스터, 명령어 혹은 
데이터만 담을 수 있는 메모리 버퍼 레지스터와는 다르게 모든 내용의 데이터를 담을 수 있다
7. 스택 포인터
- 특별한 주소 지정에 사용
- 스택과 스택 포인터를 이용하여 스택 주소 지정 방식을 사용하는데 이때 스택 포인터는
스택의 꼭대기를 가르키며 어디까지 차있는지 표시하게 된다
8. 베이스 레지스터
- 변위 주소 지정 방식에 사용
1. 상대 주소 지정 방식
- 오퍼랜드 필드의 값(변위)과 프로그램 카운터의 값을 더하여 유효 주소를 얻음
2. 베이스 레지스터 주소 지정 방식
- 오퍼랜드 필드의 값(변위)과 베이스 레지스터의 값을 더하여 유효 주소를 얻음

11강
 명령어 사이클과 인터럽트

명령어 사이클
- 프로그램 속 명령어들은 일정한 주기가 반복되며 실행되는데 이 주기를 명령어 사이클이라고 한다
인터럽트
- CPU가 꼭 주목해야 할 때, CPU가 얼른 처리해야 할 다른 작업이 생겼을 때 발생
- 현재 진행중인 일을 멈추고, 다른 일을 먼저 처리한다
1. 동기 인터럽트(예외)
- CPU가 예기치 못한 상황을 접했을 때 발생
- 현재 실행중인 프로세스에서 예외가 발생했을 때(0으로 나눔 등)
2. 비동기 인터럽트(하드웨어 인터럽트)
- 주로 입출력장치에 의해 발생
- 입, 출력 완료시에 발생
- 입출력 작업 도중에도 주기적으로 완료여부를 확인하지 않고 효율적으로 명령어를 처리하기 위해서 사용
- 인터럽트의 처리 순서는 다음과 같다
1. 입출력 장치는 CPU에 인터럽트 요청 신호를 보낸다
2. CPU는 실행 사이클이 끝나고 명령어를 인출하기 전 항상 인터럽트 여부를 확인
3. CPU는 인터럽트 요청을 확인하고 인터럽트 플래그를 통해 현재 인터럽트를 받아들일 수 있는지 확인
4. 인터럽트를 받아들일 수 있다면 CPU는 현재까지의 작업을 백업한다
5. CPU는 인터럽트 벡터를 참조하여 인터럽트 서비스 루틴을 실행한다
6. 인터럽트 서비스 루틴 실행이 끝나면 4에서 백업해 둔 작업을 복구하여 실행을 재개한다

12강
 빠른 CPU를 위한 설계 기법

클럭 속도
- 헤르츠(Hz) 단위로 측정
- 헤르츠(Hz)란 1초에 클럭이 반복되는 횟수
- 1초에 1번 클럭이 진행되면 1Hz
- 1초에 클럭이 100번 진행되면 100Hz
- 단순히 클럭속도만 늘린다면 속도는 올라가겠으나 발열이 심해진다

코어
- 현대적인 관점에서 CPU라는 용어를 재해석 해야 함
- 명령어를 실행하는 부품만이 아니다
- 전통적으로 명령어를 실행하는 부품은 원칙적으로 하나만 존재
- 하지만 오늘날 CPU에는 명령어를 실행하는 부품이 여러개 존재 가능
- 명령어를 실행하는 부품을 코어라는 용어로 사용
- 단순히 코어가 늘어난다고 그에 비례해서 속도가 늘어나진 않는다

스레드
- 실행 흐름의 단위
- 스레드에는 하드웨어적 스레드와 소프트웨어적 스레드로 나눌 수 있다
1. 하드웨어 스레드
- 하나의 코어가 동시에 처리하는 명령어 단위
- CPU안의 코어 자체에서 여러개의 스레드를 처리하게끔 설계되어 있다
- 논리 프로세서라고도 부른다
- 하드웨어적 멀티스레드에서 가장 중요한것은 명령어를 입력받을 여러개의 레지스터의 유무다
소프트웨어의 시분할 스레드처럼 정말 빠른속도로 멀티스레드처럼 보이는 것이 아닌
진짜로 여러개의 스레드를 동시에 처리하기 위해 명령어를 담을 여러개의 레지스터가 필요하기 때문
2. 소프트웨어 스레드
- 하나의 프로그램에서 독립적으로 실행하는 단위
- 프로그래머가 구현해야함
- 하드웨어적 멀티스레드처럼 정말 여러개의 스레드를 병렬 실행하는게 아닌 빠른 속도로
하나의 스레드가 여러개의 작업을 처리하는 시분할 방식

13강
 명령어 병렬 처리 기법

명령어 파이프라인
1. 명령어 인출
2. 명령어 해석
3. 명령어 실행
4. 결과 저장
- 같은 단계가 겹치지만 않는다면 CPU는 각 단계를 동시에 실행할 수 있다
- 파이프라인 위험이란 명령어 파이프라인에 의한 성능 향상에 실패하는 경우를 뜻한다
1. 데이터 위험
- 명령어 간의 의존성에 의해 야기
- 이전 명령어를 끝까지 실행해야만 비로소 다음 명령어를 실행할 수 있는 경우
- A = B + C >> D = A + E일때 A가 계산되기 전 D를 구할 수 없다
2. 제어 위험
- 프로그램 카운터의 갑작스러운 변화에 의해 야기
- 실행해야 하는 명령어의 주소지가 변경되는 경우
- if, switch, for등 분기문에 의해 발생되며 특히나 go to는 치명적이다
3. 구조적 위험
- 서로 다른 명령어가 같은 CPU 부품(ALU, 레지스터)를 쓰려고 할 때
- 슈퍼스칼라란 CPU 내부에 여러 개의 명령어 파이프라인을 포함한 구조로 오늘날의
멀티스레드 프로세서이다
- 파이프라인의 위험도로 의해 실제로 파이프라인 개수에 비례해서 속도가 증가하지 않는다

비순차적 명령어 처리
- 파이프라인의 중단을 방지하고 효율적인 운영을 위해 명령어를 순차적으로 처리하지 않는 기법
- CPU 스케쥴링의 알고리즘에 따라 FIFO가 아닌 특정 우선순위에 의해 명령어를 처리함

14강
 명령어 집합 구조, CISC와 RISC

명령어 집합(구조)
- CPU가 이해할 수 있는 명령어들의 모음
- 인텔 CPU 컴퓨터에서 만든 실행 파일은 아이폰에서 실행되지 않는다
- CPU의 언어와 다를바 없다
- 이 작은 차이(명령어)에서 비롯되어 명령어 해석 방식, 레지스터의 종류와 개수, 파이프라이닝의 용이성 등
하드웨어 부분까지 많은 것들이 달라진다

CISC(Complex Instruction Set Computer)
- 복잡한 명령어 집합을 활용하는 컴퓨터(CPU)
- x86, x86-64는 CISC 기반 명령어 집합 구조
- 복잡하고 다양한 명령어를 활용하기에 명령어의 크기와 형태가 다양한 기변 길이 명령어를
활용한다
- 다양하고 강력한 명령어를 활용하며, 상대적으로 적은 수의 명령어로도 프로그램을 
실행시킬 수 있다
- 메모리를 최대한 아끼며 개발해야 했던 시절에 인기가 높았으나 너무 복잡해서 명령어 파이프라이닝이
불리하다라는 치명적인 단점이 있음
- 또한 복잡하고 다양한 기능을 제공하기 때문에 명령어의 크기와 실행되기까지의 시간이 일정하지 않음
(파이프라이닝에 불리)
- 복잡한 명령어 때문에 명령어 하나를 실행하는 데에 여러 클럭 주기 필요
- 실제로 복잡한 명령어의 사용횟수는 낮음

RISC(Reduced Instruction Set Computer)
- 명령어의 종류가 적고, 짧은 규격화된 명령어 사용
- 짧고 규격화되었기에 명령어 파이프라이닝에 유리함
- 메모리 접근 최소화, 레지스터 적극 활용등 최적화가 잘 되어있음
- 명령어의 종류가 CISC보다 적기 때문에 더 많은 명령어로 프로그램을 동작시킴

- 결론적으로 CISC는 메모리을 아껴야했기에 복잡하고 오래걸리며, 파이프라이닝도 불리한
여러개의 명령어 집합이 존재했으나, 이제는 메모리의 제약에서 어느정도 벗어났기에
간단하고 실행시간이 적으며 파이프라이닝에도 유리한 적은 수의 명령어 집합이 있다

15강
 RAM의 특성과 종류

RAM의 크기
- RAM은 보조기억장치의 데이터들을 가지고와 CPU에서 실행할 데이터들을 저장하는 장치이므로
크기가 클수록 CPU에서 직접 접근할 수 있는 데이터의 양이 증가한다

RAM의 종류
1. DRAM(Dynamic RAM)
- 컴퓨터가 켜져 있어도 저장된 데이터가 동적으로 사라지는 RAM
- 데이터 소멸을 막기 위해 주기적으로 재활성화(다시 저장) 해야한다
- 일반적으로 메모리로 사용되는 RAM
- 상대적으로 소비전력이 낮고 저렴하며 집적도가 높아 대용량으로 설계하기 용이하기 때문
2. SRAM(Static RAM)
- 저장된 데이터가 정적인(사라지지 않는) RAM
- DRAM보다 일반적으로 더 빠름
- 일반적으로 캐시 메모리에 사용되는 RAM
- 상대적으로 소비전력이 높고 가격도 높으며 집적도가 낮아 대용량으로 설계할 필요는
없으나 빨라야 하는 장치에 사용
3. SDRAM(Synchronous DRAM)
- 발전된 DRAM이며 클럭 신호와 동기화된 DRAM
4. DDR SDRAM(Double Data Rate SDRAM)
- 발전된 SDRAM
- 최근 가장 대중적으로 사용하는 RAM
- 대역폭을 넓혀 속도를 빠르게 하는 SDRAM
5. DDR2 SDRAM
- DDR SDRAM의 2배 빠른 RAM
- 2의 DDR뒤에 수제곱배로 속도가 증가한다

16강 
 메모리의 주소 공간

메모리는 다음과 같은 이유로 메모리안에 있는 몇번 주소에 무엇이 있는지 전부 알 수 없다
1. 새롭게 실행되는 프로그램은 새롭게 메모리에 적재
2. 실행이 끝난 프로그램은 메모리에서 삭제
3. 같은 프로그램을 실행하더라도 실행할 때마다 적재되는 주소가 달라짐

물리 주소
- 메모리 입장에서 바라본 주소
- 말 그대로 정보가 실제로 저장된 하드웨어상의 주소
- 절대적으로 주어지는 주소값

논리 주소
- CPU와 실행중인 프로그램 입장에서 바라본 주소
- 실행 중인 프로그램 각각에게 부여된 0번지부터 시작하는 주소
- 각 프로그램마다 상대적으로 0부터 시작되는 주소값
- CPU가 이 논리 주소값을 사용한다

물리 주소와 논리 주소의 변환
- MMU(메모리 관리 장치)라는 하드웨어에 의해 반환
- MMU는 논리 주소와 베이스 레지스터값을 더하여 논리 주소를 물리 주소로 변환

메모리 보호
- 한계 레지스터에 의해 실행됨
- 프로그램의 영역을 침범할 수 있는 명령어의 실행을 막음
- 베이스 레지스터가 실행 중인 프로그램의 가장 작은 물리 주소를 저장한다면, 
한계 레지스터는 논리 주소의 최대 크기를 저장(ex 0 ~ 50이라면 51을 저장. 즉 최대 주소값의 + 1을 저장한다)
- 베이스 레지스터 값 <= 프로그램의 물리 주소 범위 < 베이스 레지스터 + 한계 레지스터 값
- CPU는 메모리에 접근하기 전 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사
- 실행 중인 프로그램의 독립적인 실행 공간을 확보하고 하나의 프로그램이 다른 프로그램을 침범하지 못하게
보호한다

17강
 캐시 메모리

저장 장치 계층 구조
1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다
2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다
3. 레지스터, RAM, USB를 비교하면 레지스터가 제일 빠르고 그다음 RAM, USB 순서이다
4. 저장 장치들은 CPU에 얼마나 가까운가를 기준으로 계층을 나눌 수 있다

캐시 메모리
- CPU와 메모리 사이에 위치한 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치
- CPU의 접근 속도는 CPU의 연산 속도에 비해 압도적으로 느리다
- CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생
- CPU가 매번 메모리에 왔다 갔다 하는 건 시간이 오래 걸리니 메모리에서 CPU가 사용할
일부 데이터를 미리 캐시 메모리로 가지고 와서 씀

계층적 캐시 메모리
- L1 ~ L3이 존재하며 L1이 용량이 가장 작고 빠르고 L3이 용량이 가장 크고 느리다
- L1, L2는 코어 내부에, L3은 코어 외부에 존재한다

참조 지역성의 원리
- CPU가 자주 사용할 법한 데이터를 예측하는 방법을 의미한다
- CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향(한번 선언한 변수를 자주 사용하는 것)이 있는 것과 접근한 메모리 공간
근처를 접근하려는 경향(공간 지역성, 같은 프로그램 내의 관련된 기능끼리 저장되는 것)이 있는 것을 바탕으로 만들어진 원리이다
- CPU가 캐시 메모리에 저장된 값을 활용할 경우를 캐시 히트라고 하며 이때 성능의 향상을 얻을 수 있다
- 포인터, 참조자등의 단점이 되는 원인중 하나
- CPU가 메모리에 직접 접근할때를 캐시 미스라고 하며 성능이 하락된다
- 캐시 적중률은 캐시 히트의 횟수 / (캐시 히트의 횟수 + 캐시 미스의 횟수)로 구할 수 있다

18강
 다양한 보조기억장치

하드 디스크
- 자기적인 방식으로 데이터 저장(자석)
- 플래터에 데이터가 저장되며 트랙과 섹터를 단위로 사용한다
- 섹터는 트랙을 나눈 단위이며 512 ~ 4096 바이트이다
- 각 플래터의 동일한 위치의 트랙들을 모은 것을 실린더라고 하며 연속된 정보는
한 실린더에 기록된다
- 헤더가 회전할 필요도 없기 때문에 연속된 정보는 한 실린더에 저장된다
- 헤더의 수는 플레터의 수 * 2과 같으며 각 면을 담당한다 

하드 디스크가 저장된 데이터에 접근하는 시간
1. 탐색 시간
- 접근하려는 데이터가 저장된 트랙의 섹터까지 헤드를 이동시키는 시간
2. 회전 지연
- 헤드가 있는 곳으로 플레터를 회전시키는 시간
3. 전송 시간
- 하드 디스크와 컴퓨터 간에 데이터를 전송하는 시간

- 위 시간은 굉장히 큰 부분을 차지한다

플래시 메모리
- 전기적으로 데이터를 읽고 쓰는 반도체 기반 저장 장치
- 하드 디스크와 달리 덮어쓰기가 불가능하다
- NAND, NOR 플래시 메모리가 각각 존재하며 NAND 플래시 메모리가 오늘날 많이 쓰인다

셀(Cell)
- 플래시 메모리에서 데이터를 저장하는 가장 작은 단위
- 이 셀이 모여 MB, GB, TB 저장 장치가 된다
- 한 셀에 1 ~ 4비트를 저장할 수 있으며 SLC, MLC, TLC, QLC로 불린다

플래시 메모리의 종류
1. SLC
- 한 셀로 두 개의 정보 표현
- 비트의 빠른 입출력
- 긴 수명
- 용량 대비 고가격
2. MLC
- 한 셀로 네 개의 정보 표현
- SCL보다 느린 입출력
- SCL보다 짧은 수명
- SCL보다 저렴
- 시중에서 많이 사용
2. TLC
- 한 셀로 여덟 개의 정보 표현
- MCL보다 느린 입출력
- MCL보다 짧은 수명
- MCL보다 저렴
- 시중에서 많이 사용

플래시 메모리의 저장 단위
- 셀 -> 페이지 -> 블록 -> 플레인 -> 다이
- 읽기/쓰기 단위와 삭제 단위가 다르다
- 읽기와 쓰기는 페이지를 단위로 하며 삭제는 블록을 단위로 한다

페이지의 상태
1. Free 상태
- 어떤 데이터도 저장하고 있지 않아 새로운 데이터를 저장할 수 있는 상태
2. Valid 상태
- 이미 유효한 데이터를 저장하고 있는 상태
3. Invalid 상태
- 유효하지 않은 데이터를 저장하고 있는 상태
- C#과 동일하게 가비지 컬렉션을 통해 메모리를 최적화한다

19강
 RAID의 정의와 종류

RAID의 정의
- 하드 디스크와 SSD로 사용하는 기술
- 데이터의 안정성 혹은 높은 성능을 위해 여러 물리적 보조기억장치를 마치 하나의
논리적 보조기억장치처럼 사용하는 기술

RAID 레벨(종류)
- RAID를 구성하는 기술등으로 다양한 넘버링이 붙는다
- 스트라이프란 마치 줄무늬처럼 분신되어 저장된 데이터를 말하며, 스트라이핑은
분산하여 저장하는 것을 말한다
- 각 RAID 레벨마다 장단점이 있다
- 어떤 상황에서 무엇을 최우선으로 원하는지에 따라 최적의 RAID 레벨은 달라질 수 있음
- 각 RAID 레벨의 대략적인 구성과 특징을 아는 것이 중요하다

1. RAID 0
- 데이터를 단순히 나누고 번갈아가며 저장하는 방식
- 입출력 속도의 향상을 얻을 수 있다
- 각 하드디스크에 병렬 처리를 함으로써 성능이 향상 된다
- 여러개로 나누어서 저장했을때 임의의 하드디스크가 고장나면 저장된 모든
프로그램을 사용하기 곤란해진다. 즉 저장된 정보가 안전하지 않다
2. RAID 1
- 미러링이라는 복사본을 만드는 방식을 사용하여 데이터를 원본과 복사본 두군데에 저장한다
다만 쓰기 속도가 느리다
- 복사본을 저장하기에 데이터가 매우 안전하다
- 복사본을 저장해야하는 만큼 사용 가능한 용량이 적어진다
3. RAID 4
- RAID 1처럼 완전한 복사본을 만드는 대신 오류를 검출하고 복구하기 위한 정보인 패리티 비트를 저장한다
- 패리티 비트를 저장한 장치를 이용해 다른 장치들의 오류를 검출하고, 오류가 있다면 복구한다
- 완전한 복사본을 저장하지 않기에 저장 가능한 용량이 RAID 1에 비해 늘어난다
- 패리티 비트를 한군데에 몰아서 저장하기에 해당 디스크의 병목 현상이 일어난다
4. RAID 5
- 패리티 정보를 분산하여 저장하는 방식
5. RAID 6
- 패리티 정보를 두종류로 나누어 저장하는 방식
- RAID 5보다 안전하지만 RAID 5보다 쓰기 속도가 느리다

20강
 장치 컨트롤러와 장치 드라이버

입출력 장치는 다음과 같은 이유로 CPU, 메모리보다 다루기가 까다롭다
1. 입출력 장치는 종류가 너무나도 많다
- 장치가 다양하면 장치마다 속도, 데이터 전송 형식 등도 다양하기에 방식을 규격화하기 어렵다
2. 일반적으로 CPU와 메모리의 데이터 전송속도는 높지만 입출력장치의 데이터 전송속도는 느리다
3. 이러한 이유로 입출력장치는 장치 컨트롤러를 통해 컴퓨터와 연결된다

장치 컨트롤러의 역할
1. CPU와 입출력장치 간의 통신중개
- 각 입출력장치의 번역가 역할 수행
2. 오류 검출
3. 데이터 버퍼링
- 버퍼링이란 전송률이 높은 장치와 낮은 장치 사이에 주고받는 데이터를 버퍼라는 임시
저장 공간에 저장하여 전송률을 비슷하게 맞추는 방법
- 전송률이 높은 장치로의 전송에는 데이터를 모았다가 한꺼번에 보내고, 전송률이 낮은
장치로의 전송에는 데이터를 모았다가 조금씩 보내는 방식

장치 컨트롤러의 구조
- 버스와 입출력장치를 연결하는 위치
1. 데이터 레지스터
- CPU와 입출력장치 사이에 주고받을 데이터가 담기는 레지스터(버퍼)
- 저장할 데이터가 많을 경우 RAM을 사용하기도 한다
2. 상태 레지스터
- 여러가지 상태를 저장한다
- 입출력장치가 입출력 작업을 할 준비가 되었는가?
- 입출력 작업이 완료되었는가?
- 입출력장치에 오류는 없었는가? 등
3. 제어 레지스터
- 입출력장치가 수행할 내용에 대한 제어 정보

장치 드라이버
- 장치 컨트롤러의 동작을 감지하고 제어하는 프로그램
- 장치 컨트롤러가 입출력장치를 연결하기 위한 하드웨어라면, 장치 드라이버는
입출력장치를 연결하기 위한 소프트웨어이다
- 장치 드라이버가 없다면 해당 입출력장치는 운영체제와 정보를 주고 받을 수 없다

21강
 다양한 입출력 방법

컴퓨터의 입출력 방식에는 크게 다음과 같은 3가지 방식이 있다
1. 프로그램 입출력
- 프로그램 속 명령어로 장치 컨트롤러와 상호작용하여 입출력장치를 제어하는 방법
- CPU가 장치 컨트롤러의 레지스터 값을 읽고 씀으로써 이루어진다
- 메모리에 저장된 정보를 하드 디스크에 백업하는 예시
 1. CPU는 하드 디스크 컨트롤러의 제어 레지스터에 쓰기 명령 내보내기
 2. 하드 디스크 컨트롤러는 하드 디스크 상태 확인 후 상태 레지스터에 준비 완료 표시
 3. CPU는 상태 레지스터를 주기적으로 읽어보며 하드 디스크의 준비 여부를 확인하며,
 하드 디스크가 준비되었을 때 백업할 메모리의 정보를 데이터 레지스터에 쓴다
- OS가 장치 컨트롤러의 레지스터들의 주소를 알기 위한 방법으로 다음과 같은
2가지 방법이 존재한다
 1. 메모리 맵 입출력
 - 메모리에 접근하기 위한 주소 공간과 입출력장치에 접근하기 위한 주소 공간을 하나의
 주소 공간으로 간주하는 방법
 - 여기서 주소 공간이란 하드 디스크 같은 물리적인 메모리가 아닌 CPU의 32비트, 64비트 같은
 주소 공간을 의미한다
 - 주소 공간중 일부를 입출력 용으로 예약해놓는다
 - 메모리 용 주소 공간에 접근하는 명령어와 입출력장치 용 주소 공간에 접근하는 명령어가 일치한다
 - 별도의 입출력 명령어가 필요하지 않음
 - 정리하자면 32비트 혹은 64비트에 해당하는 CPU의 주소 공간을 따로 나누지는 않으나 일부를
 입출력용으로 예약해놓기 때문에 실질적인 주소값은 메모리용과 입출력용이 무조건 다르다
 그렇기 때문에 특별한 명령어가 필요하지 않고 명령어의 형태가 같다
 2. 고립형 입출력
 - 메모리를 위한 주소 공간과 입출력장치를 위한 주소 공간을 분리하는 방법
 - 주소 공간을 따로 예약하지 않되, 특별한 명령어로 구분함
 - 입출력 전용 명령어 사용
 - 정리하자면 주소 공간에 따로 입출력용을 예약하지 않기 때문에 메모리용 주소값과
 입출력용 주소값이 같을 수도 있으나 특별한 명령어로 명령어의 형태가 다르다

2. 인터럽트 기반 입출력
- 하드웨어 인터럽트는 장치 컨트롤러에 의해서 발생한다
- 인터럽트 중에서도 우선순위가 존재하기 때문에 현실적으로 모든 인터럽트를 순차적으로
처리할 수 없다
- 각 하드웨어의 장치 컨트롤러와 연결되어 우선순위를 계산하는 하드웨어인 PIC를 이용하여
인터럽트들을 처리한다
- CPU가 폴링할 필요 없이 인터럽트가 올때까지 자유롭기 때문에 효율적이다

프로그램 입출력, 인터럽트 기반 입출력의 공통점
- 입출력장치와 메모리 간의 데이터 이동은 CPU가 주도하고 이동하는 데이터도
반드시 CPU를 거친다

3. DMA 입출력(Direct Memory Access)
- CPU를 거치지 않고 입출력장치가 메모리에 직접적으로 접근하는 기능
- CPU는 다른 작업을 할 수 있으므로 효율성 향상
- DMA 컨트롤러가 필요하다
- DMA 입출력 과정
 1. CPU는 DMA 컨트롤러에게 입출력 작업을 명령
 2. DMA 컨트롤러는 CPU 대신 장치 컨트롤러와 상호작용하며 입출력 작업을 수행
 3. 입출력 작업이 끝나면 DAM 컨트롤러는 인터럽트를 통해 CPU에 작업이 끝났음을 알림
- DMA 과정에서 시스템 버스를 이용하는데 시스템 버스는 공용 자원이기에 CPU와
동시에 사용이 불가능하다
- 따라서 DMA 컨트롤러는 CPU가 시스템 버스를 이용하지 않을 때 시스템 버스를 사용하거나
CPU가 일시적으로 시스템 버스를 이용하지 않도록 허락을 구하고 시스템 버스를 이용함
- 이러한 구도로 DMA 컨트롤러가 시스템 버스를 이용하는 양상을 Cycle Stealing이라고 한다

입출력 버스
- DMA 입출력시 입출력장치가 시스템 버스에 직접적으로 연결되어있다면 입출력시
2번의 시스템 버스를 이용해야하므로 이것을 줄이기 위해 입출력장치를 입출력 버스에
연결하여 DMA 컨트롤러의 시스템 버스 횟수를 줄인다

22강 
 레지스터 실습으로 대체

23강
 운영체제를 알아야 하는 이유

운영체제
- 실행할 프로그램에 필요한 자원을 할당하고 올바르게 실행되도록 돕는
커널 영역에 저장되는 특별한 프로그램
- 메모리에 프로그램을 적재, 제거할때에도 운영체제가 담당한다
- CPU 스케줄러 등을 통해서 CPU 역시 관리한다
- 입출력장치의 스케줄러 역시 담당한다
- 하드웨어와 응용 프로그램(사용자)의 사이를 연결하는 프로그램
- 운영체제가 있기에 하드웨어를 조작하는 코드를 작성할 필요가 없다

24강
 운영체제의 큰 그림

커널
- 운영체제의 핵심 서비스를 담당하는 부분을 커널이라고 하며 마치 사람의 심장, 자동차의 엔진과도 같다
- 운영체제에 속하면서 커널에 속하지 않는 대표적인 사례에 UI가 있으며, 사용자와 통신을 해야하기 때문이다

이중모드
- 운영체제는 응용 프로그램들이 자원에 접근하려 할 때 운영체제를 통해서만 접근하도록 하여 자원을 보호함
- CPU가 명령어를 실행하는 모드를 크게 사용자 모드와 커널 모드로 구분하는 방식
1. 사용자 모드
- 운영체제 서비스를 제공받을 수 없는 실행 모드
- 커널 영역의 코드를 실행할 수 없는 실행 모드
- 자원 접근 불가
2. 커널 모드
- 운영체제의 서비스를 제공받을 수 있는 실행 모드
- 자원 접근을 비롯한 모든 명령어 실행 가능

시스템 호출(콜)
- 커널 모드로 전환하여 실행하기 위해 호출하는 일종의 소프트웨어 인터럽트

운영체제의 핵심 서비스
1. 프로세스 관리
- 프로세스 == 실행 중인 프로그램 == 메모리에 적재
- 수많은 프로세스들이 동시에 실행
- 동시다발적으로 실행/생성/삭제되는 다양한 프로세스를 일목요연하게 관리
2. 자원 접근 및 할당
- CPU 스케줄링을 통하여 어떤 프로세스를 먼저, 얼마나 실행할지 결정
- 메모리을 효율적으로 사용하기 위해 페이징, 스와핑을 이용한다
- 운영체제가 지원해주는 인터럽트 서비스 루틴을 이용하여 입출력장치를 관리한다
3. 파일 시스템 관리
- 관련된 정보를 파일이라는 단위로 저장 장치에 보관
- 파일들을 묶어 폴더(디렉터리) 단위로 저장 장치에 보관

25강
 시스템 호출 실습으로 대체

26강
 프로세스 개요

포그라운드 프로세스
- 사용자가 볼 수 있는 공간에서 실행되는 프로세스
백그라운드 프로세스
- 사용자가 볼 수 없는 공간에서 실행되는 프로세스
- 사용자와의 상호작용에 의해 2가지로 나뉘며 그중 상호작용이 불가능한 프로세스를
데몬 혹은 서비스라고 한다

프로세스 제어 블록
- 모든 프로세스는 실행을 위해 CPU가 필요하나 CPU는 한정되어 있다
- 프로세스들은 돌아가며 할당된 시간만큼만 CPU를 이용
- 타이머 인터럽트가 발생하면 다음 프로세스에게 차례를 양보함
- 이를 위해 사용하는 자료구조가 프로세스 제어 블록(Process Control Block)
- 프로세스 관련 정보를 저장하는 자료 구조로써 프로세스 생성 시 커널 영역에 생성되며
종료 시 폐기됨
- 다음과 같은 정보들이 담긴다
1. 프로세스 ID(PID)
 - 특정 프로세스를 식별하기 위해 부여하는 고유한 번호
2. 레지스터 값
 - 프로세스는 자신의 실행 차례가 오면 이전까지 사용한 레지스터 중간 값을 모두 복원하여 실행을 재개함
 - 이 때 알아야 하는 프로그람 카운터, 스택 포인터 등의 값을 의미한다(이전에 계산했던 연산값, 실행해야 하는
 명령어의 주소값 등)
3. 프로세스 상태
 - 입출력 장치를 사용하기 위해 기다리는 상태, CPU를 사용하기 위해 기다리는 상태, CPU를 이용 중인 상태 등
 각 프로세스의 상태
4. CPU 스케줄링 정보
 - 프로세스가 언제, 어떤 순서로 CPU를 할당받을지에 대한 CPU 스케줄링 우선순위 및 할당 타이머 정보들
5. 메모리 정보
 - 프로세스가 어느 주소에 저장되어 있는지에 대한 정보
 - 페이지 테이블 정보
6. 사용한 파일과 입출력장치 정보
 - 할당된 입출력장치, 사용 중인 파일 정보

문맥 교환
- 인터럽트가 발생했을 때와 비슷하다
- 기존에 실행되던 프로세스 A에서 프로세스 B로 실행 순서가 넘어가는 것을 뜻한다
- 기존에 실행되던 프로세스 A는 지금까지 중간 정보를 백업
- 프로그램 카운터 등 각종 레지스터 값, 메모리 정보, 열었던 파일, 사용한 입출력장치 등
다음 차례가 왔을 때 실행을 재개하기 위한 정보들을 저장하며 이것을 문맥이라고 한다
- 뒤이어 실행할 프로세스 B의 문맥을 복구
- 이 단계에서 잡아먹는 시간이 크기 때문에 효율적으로 처리하는 것이 중요함
- 프로세스 A 실행 -> 프로세스 A의 문맥을 PCB에 저장 -> 프로세스 B의 문맥을 PCB에서 가져옴
 -> 프로세스 B 실행 -> 반복

프로세스의 메모리 영역
1. 코드 영역(텍스트 영역)
- 실행할 수 있는 코드, 기계어로 이루어진 명령어 저장
- 데이터가 아닌 CPU가 실행할 명령어가 담기기에 쓰기가 금지된 영역
- 영역의 크기가 변하지 않는 정적 영역
2. 데이터 영역
- 전역 변수와도 같이 프로그램 종료시까지 반영구적으로 저장되는 데이터들이 저장
- 영역의 크기가 변하지 않는 정적 영역
3. 힙 영역
- 동적할당 된 데이터들이 저장되는 영역
- 크기가 변할 수 있는 동적 할당 영역
- 낮은 주소에서 높은 주소로 할당
4. 스택 영역
- 지역변수들이 저장되는 영역
- 크기가 변할 수 있는 동적 할당 영역
- 높은 주소에서 낮은 주소로 할당

27강
 프로세스 상태와 계층 구조

프로세스 상태
1. 생성 상태
- 이제 막 메모리에 적재되어 PCB를 할당 받은 상태이며 실행 준비가 완료되었다면
준비 상태로 전환
2. 준비 상태
- CPU를 할당받아 실행할 수 있지만 자신의 차례가 아니기 때문에 기다리는 상태로써,
차례가 온다면 실행 상태로 전환(디스패치)
3. 실행 상태
- CPU를 할당 받아 실행중인 상태로 할당된 시간을 모두 사용시(타이머 인터럽트 발생 시)
준비 상태로, 실행 도중 입출력장치를 사용하면 입출력 작업이 끝날 때까지 대기 상태로 전환
4. 대기 상태
- 프로세스가 실행 도중 입출력장치를 사용하는 경우
- 입출력 작업은 CPU에 비해 느리기 때문에 이 경우 대기 상태로 접어듬
- 입출력 작업이 끝나면 (입출력 완료 인터럽트를 받으면) 준비 상태로 전환
5. 종료 상태
- 프로세스가 종료된 상태로 PCB, 프로세스의 메모리 영역 정리

프로세스 계층 구조
- 프로세스 실행 도중(시스템 호출을 통해) 다른 프로세스 생성 가능
- 새 프로세스를 생성한 프로세스는 부모 프로세스로, 부모 프로세스에 의해 생성된
프로세스는 자식 프로세스라고 부른다
- 부모, 자식 프로세스는 별개의 프로세스이므로 각기 다른 PID를 가지며 일부 운영체제에서는
자식 프로세스 PCB에 부모 프로세스 PID(PPID)를 명시하기도 한다
- 같은 프로그램을 두번 실행하더라도 각 프로세스는 별개이기 때문에 다른 PID를 가진다
- 자식 프로세스는 또 다른 자식 프로세스를 생성할 수 있으며 이것은 무한히 반복될 수 있으며
각기 계층적인 구조를 형성한다

프로세스 생성 기법
- 복제와 옷갈아입기
- 부모 프로세스는 fork 시스템 호출을 통해 자신의 복사본을 자식 프로세스로 생성(복제)
- fork 시스템 호출은 복사본 생성하며 부모 프로세스의 자원을 상속한다
- 자식 프로세스는 exec 시스템 호출을 통해 자신의 메모리 공간을 다른 프로그램으로 교체(옷갈아입기)
- exec 시스템 호출은 메모리 공간을 새로운 프로그램으로 덮어쓰는 것이며, 코드/데이터 영역은 실행할
프로그램의 내용으로 바뀌고 나머지 영역(힙, 스택)은 초기화된다

28강
 스레드

스레드
- 스레드는 프로세스를 구성하는 실행 흐름의 단위
- 하나의 프로세스는 하나 이상의 스레드를 가질 수 있다
- 각 스레드는 스레드 ID, 프로그램 카운터를 비롯한 레지스터 값, 스택 등 실행에 필요한
최소한의 정보를 가지고 있음(PCB에 저장된 자료중 필요한 값만을 가지며 나머지는 스레드끼리 공유한다)
- 한 프로세스의 스레드들은 모두 같은 자원을 공유한다

멀티 프로스세와 멀티 스레드(단일 스레드를 여러개의 프로세스로 실행 vs 하나의 프로세스의 멀티 스레드로 실행)
- 프로세스를 fork하면 코드/데이터 등 모든 자원이 복제되어 저장됨
- 저장된 메모리 주소를 제외하면 모든 것이 동일한 프로세스 두 개가 통째로 메모리에 적재
- 스레드들은 각기 다른 스레드 ID, 프로그램 카운터 등 별도의 실행을 위해 꼭 필요한 값이 늘어날 뿐 추가적인
메모리는 적재하지 않는다
- 프로세스끼리 통신이 가능하나 스레드가 공유하는 것처럼만큼은 효율적이지 않다

29, 30 
파이썬 코드로 프로세스, 스레드 확인하기로 대체

31강
 CPU 스케줄링

CPU 스케줄링
- 운영체제가 프로세스들에게 공정하고 합리적으로 CPU 자원을 배분하는 것

프로세스 우선순위
- 입출력 작업이 많은 프로세스(입출력 집중 프로세스)의 우선순위는 잠깐 실행후 대기 상태로
전환되기 때문에 CPU 작업이 많은 프로세스(CPU 집중 프로세스)의 우선순위보다 높다
- 각 프로세스의 우선순위는 PCB에 저장된다

스케줄링 큐
- 각 자원(CPU, 입출력 장치 등)을 사용하는 프로세스들의 우선순위를 계산하여 Queue에
그 순서를 저장해놓은것
- 준비 큐는 CPU를 이용하기 위해 준비 상태에 접어든 프로세스들이 기다리는 줄이고
대기 큐는 입출력 장치를 이용하기 위해 대기 상태에 접어든 프로세스들이 기다리는 줄이다
- 각 큐는 선입선출이 절대적 원칙이 아니며 우선순위가 중요하다

선점형과 비선점형 스케줄링
1. 선점형 스케줄링
- 현재 CPU를 사용 중인 프로세스로부터 CPU 자원을 빼앗아 다른 프로세스에 할당
- 어느 한 프로세스의 자원 독점을 막고 프로세스들에 골고루 자원을 배분할 수 있다
- 그만큼 문맥 교환 과정에서 오버헤드가 발생할 수 있다
2. 비선점형 스케줄링
- 현재 CPU를 사용 중인 프로세스의 작업이 끝날 때까지 프로세스 기다리기
- 선점형 스케줄링에 비해 문맥 교환에서 발생하는 오버헤드가 적다
- 모든 프로세스가 골고루 자원을 이용하기 어렵다

32강
 CPU 스케줄링 알고리즘

스케줄링 알고리즘 종류
1. 선입 선처리 스케줄링
- FCFS(First Come First Served) 스케줄링
- 단순히 준비 큐에 삽입된 순서대로 처리하는 비선점 스케줄링
- 먼저 CPU를 요청한 프로세스부터 CPU 할당
- 프로세스들이 기다리는 시간이 매우 길어질 수 있다는 부작용(호위 효과)
- CPU 사용 시간이 긴 프로세스가 앞에 존재한다면 의미없이 기다리는 시간이 길어짐
2. 최단 작업 우선 스케줄링
- SJF(Shortest Job First) 스케줄링
- 호위 효과를 방지하기 위해 CPU 사용 시간이 짧은 프로세스부터 실행
- 선점, 비선점 모두 가능하나 기본적으로는 비선점형으로 구현됨
3. 라운드 로빈 스케줄링
- RR(Round Robin) 스케줄링
- 선입 선처리 스케줄링 + 타임 슬라이스(Time Slice)
- 타임 슬라이스란 각 프로세스가 CPU를 사용할 수 있는 정해진 시간
- 큐에 삽입된 프로세스들은 선입선출대로 CPU를 이용하되, 정해진 시간만큼만 이용하며
아직 프로세스가 완료되지 않았다면 다시 큐의 맨 뒤에 삽입된다(문맥 교환)
- 타임 슬라이스가 너무 크면 선입 선처리 스케줄링과 다를바 없고, 타임 슬라이스가 너무 작으면
문맥교환으로 인한 오버헤드가 커지기에 타임 슬라이스의 크기가 중요하다
4. 최소 잔여 시간 우선 스케줄링
- SRT(Shortest Ramain Time) 스케줄링
- 최단 작업 우선 스케줄링 + 라운드 로빈 스케줄링
- 정해진 시간만큼 CPU를 이용하되, 다음으로 CPU를 사용할 프로세스는 남은 작업 시간이 가장
적은 프로세스를 선택
5. 우선순위 스케줄링
- 프로세스들에게 우선순위를 부여하고, 우선순위가 높은 프로세스부터 실행
- 우선순위가 같은 프로세스들은 선입선출로 실행
- 최단 작업, 최소 잔여 스케줄링들 역시 우선순위 스케줄링에 포함된다
- 먼저 큐에 포함되었어도 우선순위가 낮다면 실행을 기약할 수 없을 정도로 연기되며
이것을 기아(Starvation) 현상이라고 한다
- 기아 현상을 해결하기 위해 오랫동안 큐에서 대기한 프로세스의 우선순위를 점차 높이는
방식을 이용하며 이것을 에이징(Aging)이라고 한다
6. 다단계 큐 스케줄링
- 우선순위 스케줄링이 발전한 형태
- 우선순위 별로 여러개의 준비 큐를 사용하는 방식
- 각 큐별로 다른 스케줄링 알고리즘을 사용할 수 있다
- 프로세스의 성격, 우선순위 타입에 따라 여러가지 큐중 하나에 포함됨
- 큐에서 다른 큐로 이동이 불가능하기에 우선순위가 낮은 큐에 존재한다면
마찬가지로 기아현상을 겪을 수 있다
7. 다단계 피드백 큐 스케줄링
- 다단계 큐 스케줄링이 발전한 형태
- 큐 간의 이동이 가능한 다단계 큐 스케줄링
- CPU 집중 프로세스의 우선순위는 실행이 반복됨에 따라 상대적으로 낮아지고,
입출력 집중 프로세스의 우선순위는 덩달아 상대적으로 높아짐
- CPU 스케줄링의 가장 일반적인 형태

33강 
 프로세스 동기화

동기화란
1. 프로세스를 올바른 순서대로 실행하는 실행 순서 제어
- 위상 정렬처럼 예를 들어 읽는 프로세스와 쓰는 프로세스가 나뉠때 읽을만한 내용이 있을때
읽을 수 있기에 쓰는 프로세스가 반드시 먼저 실행되어야 한다
2. 동시에 접근해서는 안되는 자원에 하나의 프로세스만 접근하는 상호 배제
- 공유가 불가능한 자원의 동시 사용을 피하기 위한 동기화(변수값 등)
- A 프로세스가 자료에 접근시 B 프로세스가 접근할 경우 A의 수정이 제대로 반영되지 않을 수 있음

공유 자원과 임계 구역
- 여러 프로세스 혹은 스레드가 공유하는 전역 변수, 파일, 입출력장치등을 공유 자원이라고 하며
동시에 실행하면 문제가 발생하는 자원에 접근하는 코드 영역을 임계 구역이라고 한다
- 임계 구역에 동시에 접근하면 자원의 일관성이 깨질 수 있으며 이를 레이스 컨디션(Race Condition)이라고 한다

상호 배제를 위한 동기화의 세 가지 원칙
1. 상호 배제
- 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 들어갈 수 없다
2. 진행
- 임계 구역에 어떤 프로세스도 진입하지 않았다면 진입하고자 하는 프로세스는 들어갈 수 있어야한다
3. 유한 대기
- 한 프로세스가 임계 구역에 진입하고 싶다면 언젠가는 임계 구역에 들어갈 수 있어야한다
(임계 구역에 진입하기 위해 무작정 대기해서는 안된다)

34강 
 프로세스 동기화 기법

1. 뮤텍스 락
- 상호 배제를 위해 자물쇠 역할을 하는 동기화 도구이며 공유 자원이 한개인 경우
- 탈의실에 비유할 수 있다
- 뮤텍스 락의 형태는 전역 변수 하나, 함수 두개로 간단히 구현할 수 있다
- 자물쇠 역할을 하는 전역 변수 lock, 임계 구역을 잠그는 역할의 Acquire 함수, 임계 구역의
잠금을 해제하는 역할의 Release 함수로 나뉜다
 1.1 Acquire 함수
 - 프로세스가 임계 구역에 진입하기 전에 호출
 - 임계 구역이 잠겨 있다면 열릴때까지(lock이 false가 될 때까지) 임계 구역을 반복적으로 확인
 - 임계 구역이 열려 있다면 임계 구역을 잠그기(lock을 true로 바꿈)
 1.2 Release 함수
 - 임계 구역에서의 작업이 끝나고 호출
 - 현재 잠긴 임계 구역을 열기(lock을 false로 바꾸기)
- while(lock == true) { ; } 같은 경우 인터럽트가 아닌 폴링같은 경우이므로 배제한다(바쁜 대기)
2. 세마포
- 좀 더 일반화된 방식의 동기화 도구로 공유 자원이 여러개인 경우에도 적용 가능
- 임계 구역 앞에서 멈춤 신호를 받으면 잠시 기다리고, 진입 신호를 받으면 임계 구역 진입
- 세마포의 형태는 전역 변수 하나, 함수 두개로 간단히 구현 가능
- 임계 구역에 진입할 수 있는 프로세스의 개수(사용 가능한 공유 자원의 개수)를 나타내는 전역 변수 S,
임계 구역에 들어가도 좋은지, 기다려야 하는지를 알려주는 Wait 함수, 임계 구역 앞에서 기다리는 프로세스에게 
신호를 주는 Signal 함수로 구현된다
- 뮤텍스 락과 비슷한 로직이나, lock이 아닌 S의 개수가 0이하인지가 while()문의 조건이 되며 마찬가지로
바쁜 대기를 주의해야한다
- 바쁜 대기의 해결 방법은 자원을 사용할 수 없을 때 PCB를 대기 큐에 넣어 대기 상태로 만들고
자원이 생겼을 때 PCB를 준비 큐에 넣어 준비 상태로 만든다. 즉, 폴링 형태가 아닌 인터럽트 형태로 만든다
- 세마포를 활용한 실행 순서 동기화도 가능한데, 세마포의 변수 S를 0으로 두고 먼저 실행할 프로세스 뒤에
Signal 함수, 다음에 실행할 프로세스 앞에 Wait 함수를 구현하면 된다
3. 모니터
- 세마포는 매번 임계구역 앞뒤로 Wait(), Signal()을 호출해야하는 단점이 있음
- 상호 배제를 위한 동기화로는 공유자원에 접근하고자 하는 프로세스를 위한 큐를 이용하여
큐에 삽입된 순서대로 한번에 하나의 프로세스만 공유 자원을 이용한다
- 실행 순서 제어를 위한 동기화는 프로세스나 스레드의 실행 순서를 제어하기 위해 사용하는 특별한 변수인
조건 변수를 이용함
- 조건 변수를 통한 큐를 사용하되, 이 큐는 상호 배제를 위한 큐와는 다름에 유의할 것
- 조건 변수로 Wait(), Signal()을 호출할 수 있는데 각각 대기 상태로 변경하여 조건 변수 큐에 삽입하는
함수와 Wait()로 대기 상태로 접어든 조건변수를 실행 상태로 변경하는 함수다
- 큐에는 오직 하나의 프로세스만이 접근할 수 있으며 특정 프로세스 A가 아직 실행될 조건이 되지 않았을때
에는 Wait()를 호출해 실행을 중단하고, 조건이 충족되었을 때에는 Signal()을 통해 실행을 재개한다

35강
 교착 상태

교착 상태란
- 서로가 점거하고 있는 자원을 서로 기다리고 있을 때 그 어떤 프로세스도 끝까지 실행될 수
없음을 말한다
- 예를 들어 게임과 웹 브라우저가 모두 자원 A와 B가 있어야 실행이 가능한데
게임은 A를, 웹 브라우저는 B를 가지고 서로의 자원을 기다릴 때 교착 상태가 된다
- 교착 상태를 해결하기 위해서는 다음과 같은 2가지 단계를 필요로 한다
 1. 교착 상태가 발생했을 때의 상황을 정확히 표현
 - 자원 할당 그래프를 사용한다
 - 어떤 프로세스가 어떤 자원을 할당 받아 사용 중인지 확인
 - 어떤 프로세스가 어떤 자원을 기다리고 있는지 확인
 - 교착 상태가 일어났을 때 자원 할당 그래프에는 사이클이 존재한다
 2. 교착 상태가 일어나는 근본적인 이유 이해
 - 교착 상태가 발생하는 조건은 다음 4가지가 있다
  2.1 상호 배제
  - 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없는 상태 
  2.2 점유와 대기
  - 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다리는 상태
  2.3 비선점
  - 어떤 프로세스도 다른 프로세스의 자원을 강제로 빼앗지 못하는 상태
  2.4 원형 대기
  - 프로세스들이 사이클을 이루는 상태. 사이클이 무조건 교착 상태로 이어지는건 아니지만
  교착 상태는 무조건 사이클이 존재한다
- 위 4가지 조건을 모두 만족하면 교착 상태가 발생한다

36강
 교착 상태 해결 방법

교착 상태 해결
1. 예방
- 애초에 교착 상태가 발생하지 않도록 발생 조건(상호 배제, 점유와 대기, 비선점, 사이클) 중
하나를 없애버림
- 상호 배제를 없애러면 모든 자원을 공유하게 만들어야하나 현실적으로는 불가능함
- 점유와 대기를 없애려면 특정 프로세스에게 자원을 모두 할당하거나, 아예 할당하지 않아야하지만
자원의 활용률이 낮아질 수 있다
- 비선점을 없애려면 선점이 가능한 자원(ex CPU)에 한해 효과적이나 모든 자원이 선점 가능한 것은 아님(프린터 등)
- 사이클은 자원에 번호를 붙이고 오름차순으로 할당하면(낮은 번호의 자원을 가진채 높은 번호의 자원을
추가로 가질 수는 있으나 그 반대는 불가능) 없앨 수 있으나 자원에 번호를 붙이는 것도 어려울뿐더러
어떤 자원에 어떤 번호를 붙이느냐에 따라 활용률이 달라진다
- 교착 상태가 발생하지 않음은 보장할 수 있으나 부작용이 따른다
2. 회피
- 교착 상태를 무분별한 자원 할당으로 인해 발생했다고 간주함
- 배분할 수 있는 자원의 양을 고려하여 교착 상태가 발생하지 않을 만큼만 자원을 배분
- 안전 순서열 : 교착 상태 없이 프로세스들에게 안전하게 자원을 할당할 수 있는 순서
- 안전 상태 : 교착 상태 없이 모든 프로세스가 자원을 할당 받고 종료할 수 있는 상태. 안전 순서열이 존재함
- 불안전 상태 : 교착 상태가 발생할 수도 있는 상태. 안전 순서열이 존재하지 않음
- 안전 상태에서 안전 상태로 움직이는 경우에만 자원을 할당하는 방식
- 불안전 상태가 예상될 때에는 자원 할당을 거부함
3. 검출 후 회복
- 교착 상태의 발생을 인정하고 사후에 조치
- 프로세스가 자원을 요구하면 일단 할당하고 교착 상태 발생시 회복
- 선점을 통한 회복, 프로세스 강제 종료를 통한 회복의 2가지 경우가 있다
 3.1 선점을 통한 회복
 - 교착 상태가 해결될 때까지 한 프로세스씩 자원을 몰아주는 방식
 3.2 프로세스 강제 종료를 통한 회복
  3.2.1 교착 상태에 놓인 프로세스 모두 강제 종료(작업 내역을 잃을 위험)
  3.2.2 교착 상태가 해결될 때까지 한 프로세스씩 강제 종료(오버헤드)
4. 무시
- 타조 알고리즘
- 손실에 비해 예방에 드는 비용이 크다면 무시한다

37강
 연속 메모리 할당

연속 메모리 할당
- 프로세스에 연속적인 메모리 공간을 할당

스와핑
- 현재 사용하지 않는 프로세스들을 보조기억장치의 일부 영역(스왑 영역)으로 쫓아내고
그렇게 생긴 빈 공간에 새 프로세스를 적재(메모리에 적재할때 스왑인, 쫓아낼 때 스왑 아웃)
- 현재 실행하지 않는 프로세스들을 스왑 영역으로 옮기기에 프로세스들이 요구하는 메모리 공간 크기가
실제 메모리 크기보다 커도 상관없다

메모리 할당
- 프로세스는 메모리의 빈 공간에 할당되어야하는데 빈 공간이 여러개라면 다음과 같은 방식이 존재한다
1. 최초 적합
- First - Fit
- 운영체제가 메모리 내의 빈 공간을 순서대로 검색하다 최초로 적재할 수 있는 공간을 발견하면 그 공간에
프로세스를 배치하는 방식
- 검색 최소화, 빠른 할당
2. 최적 적합
- Best - Fit
- 운영체제가 빈 공간을 모두 검색해본 뒤, 적재 가능한 가장 작은 공간에 할당
3. 최악 적합
- Worst - Fit
- 운영체제가 빈 공간을 모두 검색해본 뒤, 적재 가능한 가장 큰 공간에 할당

외부 단편화
- 프로세스를 연속적으로 메모리에 할당하는 방식은 메모리를 효율적으로 사용하지 못함
- 프로세스들이 실행되고 종료되길 반복하며 메모리 사이에 프로세스를 할당하기 어려울 만큼
작은 메모리 공간들로 인해 메모리가 낭비되는 현상

외부 단편화 해결 방법
1. 메모리 압축
- 메모리 조각 모음이라고도 불리우며, 프로세스들을 적당히 재배치시켜 흩어져 있는 작은 빈 공간들을
하나의 큰 빈 공간으로 만드는 방법
- 재배치 과정에서 많은 오버헤드가 발생하고 현실적이지 않음
2. 가상 메모리 기법, 페이징
- 가장 대중적인 메모리 관리 기법

38강
 페이징을 통한 가상 메모리 관리

가상 메모리
- 실행하고자 하는 프로그램을 실제로 사용하는 일부만 적재하여 실제 물리 메모리 크기보다 더 큰 
프로세스를 실행할 수 있게 하는 기술
- 페이징, 세그멘테이션

페이징
- 외부 단편화가 발생했던 근본적인 문제는 각기 다른 크기의 프로세스를 메모리에 연속적으로
할당하였기 때문이다
- 프로세스의 논리 주소 공간을 페이지라는 일정 단위로 자르고 메모리의 물리 주소 공간을
프레임이라는 페이지와 동일한 단위로 자른 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법
- 페이징에서도 스와핑은 가능하며 스왑 인을 페이지 인, 스왑 아웃을 페이지 아웃으로 부른다
- 프로세스를 실행하기 위해 모든 페이지가 적재될 필요가 없으며, 물리 메모리보다 큰 프로세스도
실행할 수 있다
- 페이지가 불연속적으로 배치되어 있을 수 있기 때문에 프로세스를 이루는 페이지들이 어느 프레임들에
적재되어 있는지 CPU가 일일이 알 수 없다

페이지 테이블
- 페이지 번호와 프레임 번호를 짝지어 주는 이정표
- 프로세스마다 페이지 테이블이 존재함
- 물리적으로는 분산되어 있더라도 CPU 입장에서 바라본 논리 주소는 연속적으로 보임
- 프로세스르 페이지의 크기로 나눌때 나머지 부분이 존재할 수 있는데 이것으로 인해 내부 단편화가
일어날 수 있다(프로세스 크기 11, 페이지 크기 3, 마지막 페이지는 3이 아닌 2가 되어 1의 내부 단편화 발생)

PTBR
- 프로세스마다 페이지 테이블이 존재하며 CPU 내의 프로세스 테이블 베이스 레지스터가 각 페이지 테이블이
메모리에 저장된 주소값을 가지고 있다
- 페이지 테이블이 메모리에 저장되어 있으면 CPU가 페이지 테이블에 접근할 때 한번, 프레임에 접근하기 위해
한번으로 메모리 접근 시간이 두배가 된다

TLB
- CPU 곁에 존재하는 페이지 테이블의 캐시 메모리로 자주 사용하는 페이지 테이블의 일부를 가져와 저장함
- CPU가 접근하려는 논리 주소가 TLB에 있다면 TLB 히트로 메모리 접근은 한번이며 없다면 TLB 미스로
메모리 접근은 두번이 된다

페이징에서의 주소 변환
- 페이징 시스템에서 논리 주소는 페이지 번호와 변위(Offset)으로 이루어져 있으며
이것이 프레임 번호와 변위로 변환된다. 또한, 변위 값은 양쪽에서 같다

페이지 테이블 엔트리
- 페이지 테이블의 각 행을 페이지 테이블 엔트리라고 하며 페이지 번호, 프레임 번호가 담기며 그 이외에
다음과 같은 내용이 있다
1. 유효 비트
- 현재 해당 페이지에 접근 가능한지 여부. 즉, 메모리가 적재된 페이지인지 알리는 비트로
값이 1이면 메모리가 적재되었으며 0이라면 해당 페이지가 아직 보조기억장치에 있음을 알린다
- 유효 비트가 0인 페이지에 접근하면 페이지 폴트라는 인터럽트가 발생하며 인터럽트와 똑같은 다음과 같은
절차가 진행된다
 1.1 CPU는 기존의 작업 내역을 백업한다
 1.2 페이지 폴트 처리 루틴을 실행함
 1.3 페이지 처리 루틴은 접근을 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경함
 1.4 페이지 폴트를 처리했다면 이제 CPU는 해당 페이지에 접근할 수 있게 됨
2. 보호 비트
- 페이지 보호 기능을 위해 존재하는 비트로 읽기/쓰기 권한을 기록함
3. 참조 비트
- CPU가 이 페이지에 한번이라도 접근한 적이 있는지 여부를 알림. 접근한 적이 있다면 1,
없다면 0이 된다
4. 수정 비트
- CPU가 이 페이지에 데이터를 쓴 적이 있는지(수정된 적이 있는지) 여부. 수정한 적이 있다면 1,
없다면 0이 된다
- 만약 페이지의 데이터가 변경이 된다면 페이지 아웃 되거나 프로세스 종료시 해당 데이터들은
보조기억장치에 새롭게 저장해야 한다. 늘 저장하는 것은 굉장히 오버헤드가 발생하므로
수정 비트를 이용하여 저장의 여부를 알 수 있다